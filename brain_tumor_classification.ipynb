{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "179562c7",
   "metadata": {},
   "source": [
    "# Brain Tumor Classification — End-to-End (Jupyter Notebook)\n",
    "\n",
    "This notebook is a beginner-friendly, ready-to-run pipeline for brain tumor classification using PyTorch and transfer learning (ResNet18). \n",
    "It includes data loading, augmentation, model training, evaluation, and inference. **Do not use this for medical diagnosis.**\n",
    "\n",
    "Instructions:\n",
    "1. Place your dataset in the `data/` folder with subfolders `train/`, `val/`, `test/`, each containing class subfolders (e.g. `tumor/`, `no_tumor/`).\n",
    "2. Install dependencies (cell below).\n",
    "3. Run cells sequentially.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd3fa6f",
   "metadata": {},
   "source": [
    "## 1) Install dependencies\n",
    "Run the following cell if packages are not installed. In Colab, prefix with `!` or use a separate cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f25bdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell only if you need to install packages (uncomment pip lines when needed)\n",
    "# !pip install torch torchvision torchaudio\n",
    "# !pip install numpy pandas matplotlib scikit-learn pillow tqdm seaborn\n",
    "\n",
    "print('Skip installation in managed envs (Colab/Local) if already installed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714c8028",
   "metadata": {},
   "source": [
    "## 2) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cddcf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "print('Imports loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655be284",
   "metadata": {},
   "source": [
    "## 3) Data structure\n",
    "\n",
    "Place your data as:\n",
    "```\n",
    "data/\n",
    "  train/\n",
    "    tumor/\n",
    "    no_tumor/\n",
    "  val/\n",
    "    tumor/\n",
    "    no_tumor/\n",
    "  test/\n",
    "    tumor/\n",
    "    no_tumor/\n",
    "```\n",
    "Each folder should contain images (jpg/png). If you only have one folder, split into train/val/test (70/15/15) before running.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42703e71",
   "metadata": {},
   "source": [
    "## 4) Transforms & DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eef9ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(img_size=224):\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    val_transforms = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    return train_transforms, val_transforms\n",
    "\n",
    "\n",
    "def create_dataloaders(data_dir, batch_size=32, img_size=224, num_workers=2):\n",
    "    train_tf, val_tf = get_transforms(img_size)\n",
    "\n",
    "    train_dir = os.path.join(data_dir, 'train')\n",
    "    val_dir = os.path.join(data_dir, 'val')\n",
    "    test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "    train_ds = ImageFolder(train_dir, transform=train_tf)\n",
    "    val_ds = ImageFolder(val_dir, transform=val_tf)\n",
    "    test_ds = ImageFolder(test_dir, transform=val_tf)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    class_names = train_ds.classes\n",
    "    print(f'Found classes: {class_names}')\n",
    "\n",
    "    return train_loader, val_loader, test_loader, class_names\n",
    "\n",
    "# quick check (won't run until data is present)\n",
    "# train_loader, val_loader, test_loader, class_names = create_dataloaders('data', batch_size=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbf3aed",
   "metadata": {},
   "source": [
    "## 5) Model (ResNet18 transfer learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9d20a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes, pretrained=True):\n",
    "    model = models.resnet18(pretrained=pretrained)\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "# Example: model = build_model(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd47e22f",
   "metadata": {},
   "source": [
    "## 6) Training function\n",
    "\n",
    "This training loop saves the best model by validation accuracy to `outputs/best_model.pth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "559e968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_dir='data', epochs=10, batch_size=32, lr=1e-3, img_size=224, device=None, out_dir='outputs'):\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    train_loader, val_loader, test_loader, class_names = create_dataloaders(data_dir, batch_size, img_size=img_size)\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    model = build_model(num_classes).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=3)\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"Epoch {epoch}/{epochs}\")\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data).item()\n",
    "            total += inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = running_corrects / total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_corrects += torch.sum(preds == labels.data).item()\n",
    "                val_total += inputs.size(0)\n",
    "\n",
    "        val_epoch_loss = val_loss / val_total\n",
    "        val_epoch_acc = val_corrects / val_total\n",
    "\n",
    "        print(f\"Train loss: {epoch_loss:.4f} acc: {epoch_acc:.4f} | Val loss: {val_epoch_loss:.4f} acc: {val_epoch_acc:.4f}\")\n",
    "\n",
    "        # Scheduler step\n",
    "        scheduler.step(val_epoch_loss)\n",
    "\n",
    "        # deep copy best\n",
    "        if val_epoch_acc > best_acc:\n",
    "            best_acc = val_epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            torch.save(model.state_dict(), os.path.join(out_dir, 'best_model.pth'))\n",
    "\n",
    "    print(f\"Training complete. Best val acc: {best_acc:.4f}\")\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    torch.save(model.state_dict(), os.path.join(out_dir, 'final_model.pth'))\n",
    "\n",
    "    return model, class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d847d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found classes: ['no', 'yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [08:17<00:00,  5.29s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.1900 acc: 0.9337 | Val loss: 0.0479 acc: 0.9762\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [08:11<00:00,  5.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0728 acc: 0.9713 | Val loss: 0.2318 acc: 0.9286\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [07:17<00:00,  4.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0916 acc: 0.9693 | Val loss: 0.0624 acc: 0.9762\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [12:03<00:00,  7.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0396 acc: 0.9870 | Val loss: 0.0655 acc: 0.9762\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [07:46<00:00,  4.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0563 acc: 0.9803 | Val loss: 0.0166 acc: 1.0000\n",
      "Training complete. Best val acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model,class_names=train(data_dir=\"data\",epochs=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf729d7",
   "metadata": {},
   "source": [
    "## 7) Evaluation on test set\n",
    "\n",
    "This cell prints classification report and plots a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5fc20eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model_path, data_dir='data', batch_size=32, img_size=224, device=None):\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    train_loader, val_loader, test_loader, class_names = create_dataloaders(data_dir, batch_size, img_size=img_size)\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    model = build_model(num_classes)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            y_true.extend(labels.numpy().tolist())\n",
    "            y_pred.extend(preds.cpu().numpy().tolist())\n",
    "\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c6071a",
   "metadata": {},
   "source": [
    "## 8) Single-image inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07ada3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def load_image(image_path, img_size=224):\n",
    "    tf = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    return tf(img).unsqueeze(0)\n",
    "\n",
    "\n",
    "def predict(image_path, model_path, num_classes, class_names, device=None):\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    model = build_model(num_classes)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    img_t = load_image(image_path)\n",
    "    img_t = img_t.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img_t)\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        conf, pred = torch.max(probs, 1)\n",
    "\n",
    "    return class_names[pred.item()], conf.item()\n",
    "\n",
    "# Example usage (run after training):\n",
    "# label, conf = predict('path/to/img.jpg', 'outputs/best_model.pth', num_classes=2, class_names=['no_tumor','tumor'])\n",
    "# print(label, conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9597877d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_tumor 0.9894247055053711\n"
     ]
    }
   ],
   "source": [
    "# Example usage (run after training):\n",
    "label, conf = predict(r'C:\\Users\\Dell\\Downloads\\Brain_tumor\\data\\train\\no\\No12.jpg', 'outputs/best_model.pth', num_classes=2, class_names=['no_tumor','tumor'])\n",
    "print(label, conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aa95c1",
   "metadata": {},
   "source": [
    "## 9) Tips & next steps\n",
    "\n",
    "- Start with a small subset of data to quickly validate the pipeline.\n",
    "- Use GPU if available (Colab provides free GPUs).\n",
    "- If classes are imbalanced, consider `torch.utils.data.WeightedRandomSampler` or class weights in loss.\n",
    "- Try stronger augmentations, or different backbones (ResNet34, EfficientNet) for better accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "Happy training! If you want, I can also create a Colab-ready notebook link or a ZIP of all project files.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
